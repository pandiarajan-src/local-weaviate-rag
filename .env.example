# --- Weaviate Configuration ---
# Connection scheme (http or https - use https in production)
WEAVIATE_SCHEME=http
WEAVIATE_HOST=localhost
WEAVIATE_PORT=8080
WEAVIATE_GRPC_PORT=50051
# SECURITY: Change this to a strong, unique API key (min 16 chars)
WEAVIATE_API_KEY=your-secure-api-key-here

# --- OpenAI Configuration ---
# Your OpenAI API key - keep this secure and never commit to version control
OPENAI_API_KEY=sk-your-actual-openai-key-here
# Optional: Custom base URL (e.g., for Azure OpenAI or proxy)
OPENAI_BASE_URL=
# Embedding model for text vectorization
OPENAI_EMBED_MODEL=text-embedding-3-small
# Chat completion model for generating answers
OPENAI_COMPLETIONS_MODEL=gpt-4o

# --- API Configuration ---
# Port for the FastAPI server
API_PORT=8001

# --- RAG Configuration ---
# Name of the Weaviate collection to store documents
RAG_COLLECTION=Documents
# Target number of tokens per text chunk (balance between context and granularity)
CHUNK_TOKENS=400
# Number of tokens to overlap between adjacent chunks (helps with context continuity)
CHUNK_OVERLAP=60
# Hybrid search balance: 0.0=keyword only (BM25), 1.0=vector only, 0.5=balanced
HYBRID_ALPHA=0.5
# Number of chunks to retrieve from search
TOP_K=5
# Maximum chunks to include in LLM context (to avoid token limits)
MAX_CONTEXT_CHUNKS=6
